{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)\n",
    "\n",
    "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b37da10-c72c-49a6-83b3-91ed9504689d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partial_text = joined_text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b351bd43-00b3-4421-b572-b633849b382c",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_word = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_word.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
    "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)  # for each sample a boolean for each possible next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758caffb-288e-4c16-878d-f969fde3d081",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_word[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89102ca3-b2fe-4a34-97c2-666164405ae8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1326/1326 [==============================] - 347s 260ms/step - loss: 7.2461 - accuracy: 0.0604\n",
      "Epoch 2/10\n",
      "1326/1326 [==============================] - 335s 253ms/step - loss: 7.4470 - accuracy: 0.0883\n",
      "Epoch 3/10\n",
      "1326/1326 [==============================] - 349s 263ms/step - loss: 7.5690 - accuracy: 0.1006\n",
      "Epoch 4/10\n",
      "1326/1326 [==============================] - 336s 253ms/step - loss: 7.5587 - accuracy: 0.1083\n",
      "Epoch 5/10\n",
      "1326/1326 [==============================] - 343s 259ms/step - loss: 7.3973 - accuracy: 0.1187\n",
      "Epoch 6/10\n",
      "1326/1326 [==============================] - 339s 256ms/step - loss: 7.1945 - accuracy: 0.1297\n",
      "Epoch 7/10\n",
      "1326/1326 [==============================] - 339s 255ms/step - loss: 6.9307 - accuracy: 0.1443\n",
      "Epoch 8/10\n",
      "1326/1326 [==============================] - 341s 257ms/step - loss: 6.6039 - accuracy: 0.1638\n",
      "Epoch 9/10\n",
      "1326/1326 [==============================] - 342s 258ms/step - loss: 6.2665 - accuracy: 0.1870\n",
      "Epoch 10/10\n",
      "1326/1326 [==============================] - 339s 256ms/step - loss: 5.8945 - accuracy: 0.2125\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X, y, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be143d5-2869-4676-b347-eb09da09a821",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1326/1326 [==============================] - 421s 316ms/step - loss: 5.5365 - accuracy: 0.2450\n",
      "Epoch 2/5\n",
      "1326/1326 [==============================] - 428s 323ms/step - loss: 5.2118 - accuracy: 0.2751\n",
      "Epoch 3/5\n",
      "1326/1326 [==============================] - 426s 321ms/step - loss: 4.9456 - accuracy: 0.3037\n",
      "Epoch 4/5\n",
      "1326/1326 [==============================] - 427s 322ms/step - loss: 4.6771 - accuracy: 0.3346\n",
      "Epoch 5/5\n",
      "1326/1326 [==============================] - 426s 322ms/step - loss: 4.5058 - accuracy: 0.3530\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, batch_size=128, epochs=5, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"text_gen_model2.h5\")\n",
    "with open(\"history2.p\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"text_gen_model2.h5\")\n",
    "history = pickle.load(open(\"history2.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "possible = predict_next_word(\"I will have to look into this thing because I\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will\n",
      "can\n",
      "had\n",
      "don\n",
      "did\n"
     ]
    }
   ],
   "source": [
    "for idx in possible:\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30d8a2cb-90cc-4698-8418-76ec38384450",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c868ebb-be16-4d4f-84df-196d983e09c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I will have to look into this thing because I could see the we are president but could just more dubious from new deals a lower presidential bid the us president were just as william when she had his hands place in her state from national bureau it has been one with my party to will say it would could win all war us this and this was if you was sure the importance for a if that has made a lead against those people and what trump can t take their effect is that is that he is to be we will have president obama who s polling better'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"I will have to look into this thing because I\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1327b41d-3b8b-4064-8d9f-782a7a07417a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The president of the United States announced yesterday that he won a president a president reached which cnn president a national stretch year implicit were also discuss before it one we would have a boost a man and raising the common part he would need for 50 and if i look a results but now this results who 50 about their ideas the go from systems if not that william when a us we can see all hollande to have served in american terrorist attacks the campaign was doing its foreign relations on their members are in a man is so under its you go a more control of clinton'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"The president of the United States announced yesterday that he\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bd4036c-128d-4c4d-9d81-9584aa45b6b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american\n",
      "the\n",
      "our\n",
      "us\n",
      "president\n"
     ]
    }
   ],
   "source": [
    "for idx in predict_next_word(\"The president will most likely not be there to help\", 5):\n",
    "    print(unique_tokens[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}